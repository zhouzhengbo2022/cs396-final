# In order to determine the appropriate method for filling in the missing values, the following commands were run:
#OPTION 1: set missing values to 0
#dataset[is.na(dataset)] <- 0
# OPTION 2: set missing values to the average of column
numeric_cols <- sapply(dataset, is.numeric) # determine which columns are numeric
numeric_column_names <- names(dataset[, numeric_cols]) # get the names of those columns
for(name in numeric_column_names) {
column <- dataset[[name]]
has_na <- is.na(column)
missing_data_result <- any(has_na) # determine if the numeric column have missing values
if(missing_data_result) {
column_average <- mean(column, na.rm=TRUE) # get the average from the remaining observations
dataset[[name]][is.na(column)] <- column_average # set any missing values in the column to the average
}
}
# verify there are no remaining missing values
any(is.na(dataset))
# scatter plot matrix, histogram and coorelation
pairs.panels(dataset)
model <- lm(Page.Total.Likes ~ Post.Month+
Post.Weekday+
Post.Hour+
Paid+
Total.Reach+
Total.Impressions+
Engaged.Users+
Consumers+
Consumptions+
Impressions.for.Users.with.Likes+
Reach.by.Users.with.Likes+
Users.with.Likes.and.Engagement+
Comment+
Like+
Share+
Total.Interactions,
data=dataset)
summary(model)
knitr::opts_chunk$set(echo = TRUE)
install.packages("mosaic") # if not done once already install.packages("curl") # if not done once already library(mosaic)
install.packages("mosaic")
#install.packages("mosaic") # if not done once already install.packages("curl") # if not done once already library(mosaic)
library(readr)
install.packages("curl")
#install.packages("mosaic") # if not done once already install.packages("curl") # if not done once already library(mosaic)
library(readr)
#install.packages("mosaic") # if not done once already install.packages("curl") # if not done once already
library(mosaic)
library(readr)
Online <- read_csv("https://nhorton.people.amherst.edu/ips9/data/chapter01/EG01-07ONLINE.csv")
Online_data <- data.frame(Source = c(rep("Google", 406), rep("Library", 75), rep("Wikipedia", 52), rep("Other", 19)))
tally(~ Online_data, margins = TRUE)
options(digits = 2)
tally(~ Online_data, format = "percent", margins = TRUE)
gf_histogram(~ Source, data = Online_data, stat = "count")
Online_Percent <-
read_csv("https://nhorton.people.amherst.edu/ips9/data/chapter01/EG01-08ONLINE.csv")
Online_Percent <- Online %>%
mutate(Count = 100 * Count/sum(Count)) %>% rename(Percent = Count)
Preferences <- ggplot(Online_Percent, aes(x = "", y = Percent, fill = factor(Source))) + geom_bar(width = 1, stat = "identity")
Preferences + coord_polar(theta="y") + labs(fill = "Source") + theme_void()
SCF <- read_csv("https://nhorton.people.amherst.edu/ips9/data/chapter01/EG01-11SCF.csv") SCF_Treatment <- SCF %>%
SCF <- read_csv("https://nhorton.people.amherst.edu/ips9/data/chapter01/EG01-11SCF.csv") SCF_Treatment <- SCF %>%
SCF <- read_csv("https://nhorton.people.amherst.edu/ips9/data/chapter01/EG01-11SCF.csv") SCF_Treatment <- SCF%>%
SCF <- read_csv("https://nhorton.people.amherst.edu/ips9/data/chapter01/EG01-11SCF.csv")
SCF_Treatment <- SCF %>%
filter(Treatment == "SCF")
with(data = SCF_Treatment, stem(Absorption))
IQ <- read_csv("https://nhorton.people.amherst.edu/ips9/data/chapter01/EG01-14IQ.csv")
levels <- c(75, 85, 95, 105, 115, 125, 135, 145, 155) labels <- as.factor(seq(from = 80, to = 150, by = 10)) IQ_Count <- IQ %>%
IQ <- read_csv("https://nhorton.people.amherst.edu/ips9/data/chapter01/EG01-14IQ.csv")
levels <- c(75, 85, 95, 105, 115, 125, 135, 145, 155)
labels <- as.factor(seq(from = 80, to = 150, by = 10))
IQ_Count <- IQ %>%
mutate(Class = cut(IQ, levels, labels = labels))
gf_bar(~ Class, data = IQ_Count)
Customer_Calls <-
read_csv("https://nhorton.people.amherst.edu/ips9/data/chapter01/EG01-16CALLS.csv") head(Customer_Calls, 80)
Customer_Calls <-
read_csv("https://nhorton.people.amherst.edu/ips9/data/chapter01/EG01-16CALLS.csv")
head(Customer_Calls, 80)
Customer_Calls %>%
filter(length <= 1200) %>%
gf_histogram(~ length, binwidth = 5) %>%
gf_labs(x = "Service time (seconds)", y = "Count of calls")
favstats(~ IQ, data = IQ)
favstats(~ IQ, data = IQ)
favstats(~ length, data = Customer_Calls)
College <- read_csv("https://nhorton.people.amherst.edu/ips9/data/chapter01/EG01-19COLLEGE.csv")
gf_dhistogram(~ Undergrads, data = College)
College %>%
filter(Undergrads == max(Undergrads))
with(College, stem(UGradPerThou))
College <- read_csv("https://nhorton.people.amherst.edu/ips9/data/chapter01/EG01-19COLLEGE.csv")
gf_dhistogram(~ Undergrads, data = College)
College %>%
filter(Undergrads == max(Undergrads))
with(College, stem(UGradPerThou))
College %>% filter(UGradPerThou > 76)
TTS24 <- read_csv("https://nhorton.people.amherst.edu/ips9/data/chapter01/EG01-23TTS24.csv with(TTS24, stem(Time, scale = 2))
TTS24 <- read_csv("https://nhorton.people.amherst.edu/ips9/data/chapter01/EG01-23TTS24.csv
with(TTS24, stem(Time, scale = 2))
TTS24 <- read_csv("https://nhorton.people.amherst.edu/ips9/data/chapter01/EG01-23TTS24.csv")
with(TTS24, stem(Time, scale = 2))
TTS24 <- read_csv("https://nhorton.people.amherst.edu/ips9/data/chapter01/EG01-23TTS24.csv")
with(TTS24, stem(Time, scale = 1))
TTS24 <- read_csv("https://nhorton.people.amherst.edu/ips9/data/chapter01/EG01-23TTS24.csv")
with(TTS24, stem(Time, scale = 2))
TTS24 <- read_csv("https://nhorton.people.amherst.edu/ips9/data/chapter01/EG01-23TTS24.csv")
with(TTS24, stem(Time, scale = 3))
TTS24 <- read_csv("https://nhorton.people.amherst.edu/ips9/data/chapter01/EG01-23TTS24.csv")
with(TTS24, stem(Time, scale = 1))
TTS24 <- read_csv("https://nhorton.people.amherst.edu/ips9/data/chapter01/EG01-23TTS24.csv")
with(TTS24, stem(Time, scale = 2))
library(statnet)
?statnet # About the package
# -------------------------------------------------------------------------------------------------
# Set the working directory
# Session > Set Working Directory > To Source File Location
# -------------------------------------------------------------------------------------------------
list.files() # List the files in the current working directory to see if you're in the right directory
# ----------------------------------------------------------------------------------------------------
######################## PART I: Building and Visualizing the Networks ########################
# ----------------------------------------------------------------------------------------------------
# Dependent variable:
# Responses to the question:
# “List up to 5 employees who you rely on the most for help or advice at work.”
# Note that participants were limited to selecting at most five respondents.
adviceEdgelist <- read.csv("adviceEdgelist.csv")
# View the first rows of the edgelist to make sure it imported correctly:
head(adviceEdgelist)
# Convert the edgelist to a network object in statnet format:
advice <- as.network.matrix(adviceEdgelist, matrix.type = "edgelist")
advice # View a summary of the network object
# Independent variables:
# Load node attributes, and store them in the advice network object we have created
set.vertex.attribute(advice, "department",read.csv("departmentNode.csv",stringsAsFactors=FALSE)$department) # Categorical variable for department
set.vertex.attribute(advice, "leader",read.csv("leaderNode.csv")$leader) # Indicator variable for department leader
set.vertex.attribute(advice, "tenure",read.csv("tenureNode.csv")$tenure) # Years tenure
set.vertex.attribute(advice, "office",read.csv("officeNode.csv")$office) # Indicator variable for whether they are located in the main or secondary office
set.vertex.attribute(advice, "female",read.csv("femaleNode.csv")$female) # Indicator variable for female vs. male
advice # These five variables should now be listed as vertex attributes when viewing the summary of the network
# Double-check the values for all of the node variables
get.vertex.attribute(advice,"department")
get.vertex.attribute(advice,"leader")
get.vertex.attribute(advice,"tenure")
get.vertex.attribute(advice,"office")
get.vertex.attribute(advice,"female")
# Finally, we will import data on the counts of direct messages sent between two employees
# The file "messageEdgelist.csv" contains a messaging edgelist, that we will convert to a matrix
# Statnet allows adjacency matrices with valued ties to be used as predictors (edge covariates) in ERGMs
messageEdgelist <- read.csv("messageEdgelist.csv")
head(messageEdgelist) # Check the first five rows of the edgelist. Third column is the message count
messages <- matrix(nrow = 66, ncol = 66) # Number of Direct messages sent from i to j
for (i in 1:nrow(messageEdgelist)) { # Read from edgelist
messages[messageEdgelist$SenderId[i], messageEdgelist$ReceiverId[i] ] <- as.numeric(messageEdgelist$MessagesSent[i])
}
for (i in 1:66) { # Remove self-ties (messages sent to self)
messages[i,i] <- as.numeric(0)
}
hundreds_messages <- messages / 100 # Change weights to represent hundred of messages sent
# This will make viewing/interpreting ergm coefficients easier
# ---------------------------------------------------------------------------------------
# Basic descriptive information
# ---------------------------------------------------------------------------------------
summary(advice, print.adj = FALSE)           # summarize the advice From You network
# ---------------------------------------------------------------------------------------
# Visualize networks
# ---------------------------------------------------------------------------------------
library('igraph') # Ignore messages on any objects that are masked
# Set default plot options
igraph_options(vertex.size = 9, vertex.color = 'grey', # vertex.size changes the size of nodes; vertex.color changes the color of nodes
edge.color='gray80', edge.arrow.size=.4, # edge.color changes the color of ties; edge.arrow.size changes the size of tie arrow heads
vertex.label = NA)                       # vertex.label = NA specifies not to display vertex labels in the plot
# Plot the Advice network
advice_igraph <- graph.adjacency(as.matrix.network(advice)) # make an igraph network object from statnet network object
advice_igraph <- set_vertex_attr(advice_igraph,"female",value = read.csv("femaleNode.csv")$female)
net_layout <- layout_with_fr(advice_igraph) # Calculates and stores a spring-embedded layout
# We will re-use this same layout for each plot, so nodes are always in the same place
plot(advice_igraph, layout=net_layout, edge.color='black', vertex.label = V(advice_igraph))
# Plot the Advice network with node coloring based on sex
V(advice_igraph)$color = ifelse (V(advice_igraph)$female ==1, " orange ", " grey ")
plot(advice_igraph, layout=net_layout, edge.color='black', vertex.label = V(advice_igraph))
# Plot the network of who messages whom
# One unit of weight is 100 messages
messages_igraph <- graph.adjacency(messages, weighted = TRUE) ## weighted = TRUE creates edge weight in the igraph object
## below because it is added not only edge weight, but also changed the transparency of edges, it will take more time to plot
## also, if you use zoom in RStudio, it may take about 1 minute until you see the plot.
plot(messages_igraph, layout=net_layout, edge.color = adjustcolor('blue',alpha=.2), vertex.label = V(advice_igraph), edge.width=log(E(messages_igraph)$weight), edge.arrow.width =.2)
# -------------------------------------------------------------------------------------------------
######################## PART II: Build the ERGM models ########################
#
# R vignette for more details: https://cran.r-project.org/web/packages/ergm/ergm.pdf
# -------------------------------------------------------------------------------------------------
detach(package:igraph) # Remove the 'igraph' package from your environment.
library(statnet)
options(ergm.loglik.warn_dyads=FALSE) #Whether or not a warning should be issued when sample space constraints render the observed number of dyads ill-defined
# Ergm Terms are statistics: They are some deterministic function of the ties, node attributes, and edge covariates of a network.
help("ergm-terms",package = "ergm") # Documentation that contains definitions for all of the terms we are using
# ex. what does "mutual" test and how is it calculated
# We will use the ergm-terms to perform hypothesis testing using ERGMs
# But we can note that any of the ERGM terms can also be examined directly for your observed network, by creating a formula in R
# Look at Endogenous statistics: terms based on only ties in the advice network
summary(advice ~ edges)                     # Number of edges (ties)
summary(advice ~ mutual)                    # Number of pairs of reciprocated ties
summary(advice ~ odegree(0:5))              # Outdegree distribution. (# of nodes with outdegree of 0, # nodes outdegree of 1, etc.)
# Remember, respondents could nominate at most five employees in our survey
summary(advice ~ idegree(0:65))             # Indegree distribution.
summary(advice ~ gwodegree(log(2),fixed=T)) # One parameter summarizing outdegree distribution - tendency against outdegree hubs
summary(advice ~ gwidegree(log(2),fixed=T)) # One parameters summarizing indegree distribution - tendency against indegree hubs
summary(advice ~ desp(1:5))                 # Pairs of nodes with one shared partner, two shared partners, etc.
summary(advice ~ dgwesp(log(2),fixed = T))  # One parameter summarizing
# Look at Exogenous statistics: terms based on advice ties AND other ties / node attributes
summary(advice ~ nodeicov("office"))             # Ties directed towards employees at the main office (as opposed to secondary office)
summary(advice ~ nodeocov("office"))             # Ties originating from employees at the main office (as opposed to secondary office)
summary(advice ~ nodematch("female"))            # Number of ties between people of the same sex
summary(advice ~ nodematch("department"))        # Number of ties between people working in the same department
summary(advice ~ nodemix("leader",levels2=NULL)) # Number of ties between different combinations of leaders(1) and non-leaders(0)
summary(advice ~ diff("tenure"))                 # Total difference in tenure: sum of (sender's tenure - receivers-tenure) for all ties
summary(advice ~ edgecov(hundreds_messages))     # Total messages sent: sum of (messages sent from sender to receiver)/100 for all Advice ties
# e.g., a total of 5669 messages were sent from employees to those they go to for advice during the observed period
# The above are statistics - counts of these patterns for our networks
# What fitting the ERGM model will tell is whether these counts are relatively high/low
# in comparison to what we would expect based on random chance, controlling for the other effects in our model.
# This type of analysis can be helpful for understanding your network, as well as troubleshooting issues with ERGM regression
# The following commands do model estimation for ERGMs.
# This may take a second. Text will print in-console to update you on progress in model estimation.
model1 <- ergm(advice ~ edges                 # This is  a tendency towards a greater number of advice ties existing. Based on a statistic counting the number of ties.
# Structural patterns
+ mutual                      # This is a tendency towards reciprocity for the advice ties. Based on a statistic counting the number of reciprocated ties.
+ edgecov(hundreds_messages)  # This is the effect of every 100 messages sent from i->j on likelihood of an advice tie. Based on a weighted sum of advice ties x 100s of messages sent
+ nodemix("leader",base = 3)
# Model constraints
, constraints =~ bd(maxout=5) # This constraint enforces the maximum outdegree is 5
)
summary(model1)
## Convert a log-odds (e.g., -2.73064) ratio to an odds ratio
exp(-2.73064)
model2 <- ergm(advice ~  # This model will be slower to estimate than model 1
# Expect roughly 2-7 minutes. If it gets stuck for longer than that, try hitting "stop" and re-running it
# Structural patterns
# edges
mutual
+ gwidegree(log(2), fixed = T)                 # Inverted preferential attachment (indegree)
+ gwodegree(2, fixed = T, cutoff = 5)              # Inverted preferential attachment (outdegree)
+ dgwesp(log(2), type = "OTP", fixed = T, cutoff =5)    # A modified version of Outgoing Two Path(i->j + i->k->j) structures. Geometrically weighted version of transitivity
# Node attribute effects
+ nodematch("female")                                   # Homophily on a categorical variable
+ nodemix("leader", base = 3)                           # Mixing matrix of all different combinations of node attributes (ex. A -> A ties, A-> B ties, B -> A ties, B -> B ties).
+ nodematch("department")
+ nodeicov("office")                                    # Covariance between in-degree of nodes and attributes of nodes
+ nodeocov("office")                                    # Covariance between out-degree of nodes and attributes of nodes
+ diff("tenure")                                        # Difference is computed as (tenure_i - tenure_j) i: sending node, j: receiving node
+ edgecov(hundreds_messages)                            # Covariance between edges of two networks (predictor can be continous)
# Constraints on network
, constraints =~ bd(maxout=5)                           # This constraint enforces the maximum outdegree is 5
# Control settings for MCMC-MLE algorithm
, control = control.ergm(MCMC.effectiveSize = 50)
)
summary(model2)
# Easy side-by-side model comparison:
library(texreg)
screenreg(list("model1"=model1,"model2"=model2))
adviceEdgelist <- read.csv("adviceEdgelist.csv")
# View the first rows of the edgelist to make sure it imported correctly:
head(adviceEdgelist)
# Convert the edgelist to a network object in statnet format:
advice <- as.network.matrix(adviceEdgelist, matrix.type = "edgelist")
advice # View a summary of the network object
# Independent variables:
# Load node attributes, and store them in the advice network object we have created
set.vertex.attribute(advice, "department",read.csv("departmentNode.csv",stringsAsFactors=FALSE)$department) # Categorical variable for department
set.vertex.attribute(advice, "leader",read.csv("leaderNode.csv")$leader) # Indicator variable for department leader
set.vertex.attribute(advice, "tenure",read.csv("tenureNode.csv")$tenure) # Years tenure
set.vertex.attribute(advice, "office",read.csv("officeNode.csv")$office) # Indicator variable for whether they are located in the main or secondary office
set.vertex.attribute(advice, "female",read.csv("femaleNode.csv")$female) # Indicator variable for female vs. male
advice # These five variables should now be listed as vertex attributes when viewing the summary of the network
# Double-check the values for all of the node variables
get.vertex.attribute(advice,"department")
get.vertex.attribute(advice,"leader")
get.vertex.attribute(advice,"tenure")
get.vertex.attribute(advice,"office")
get.vertex.attribute(advice,"female")
# Finally, we will import data on the counts of direct messages sent between two employees
# The file "messageEdgelist.csv" contains a messaging edgelist, that we will convert to a matrix
# Statnet allows adjacency matrices with valued ties to be used as predictors (edge covariates) in ERGMs
messageEdgelist <- read.csv("messageEdgelist.csv")
head(messageEdgelist) # Check the first five rows of the edgelist. Third column is the message count
messages <- matrix(nrow = 66, ncol = 66) # Number of Direct messages sent from i to j
for (i in 1:nrow(messageEdgelist)) { # Read from edgelist
messages[messageEdgelist$SenderId[i], messageEdgelist$ReceiverId[i] ] <- as.numeric(messageEdgelist$MessagesSent[i])
}
for (i in 1:66) { # Remove self-ties (messages sent to self)
messages[i,i] <- as.numeric(0)
}
hundreds_messages <- messages / 100
summary(advice, print.adj = FALSE)           # summarize the advice From You network
# ---------------------------------------------------------------------------------------
# Visualize networks
# ---------------------------------------------------------------------------------------
library('igraph') # Ignore messages on any objects that are masked
# Set default plot options
igraph_options(vertex.size = 9, vertex.color = 'grey', # vertex.size changes the size of nodes; vertex.color changes the color of nodes
edge.color='gray80', edge.arrow.size=.4, # edge.color changes the color of ties; edge.arrow.size changes the size of tie arrow heads
vertex.label = NA)
advice_igraph <- graph.adjacency(as.matrix.network(advice)) # make an igraph network object from statnet network object
advice_igraph <- set_vertex_attr(advice_igraph,"female",value = read.csv("femaleNode.csv")$female)
net_layout <- layout_with_fr(advice_igraph) # Calculates and stores a spring-embedded layout
# We will re-use this same layout for each plot, so nodes are always in the same place
plot(advice_igraph, layout=net_layout, edge.color='black', vertex.label = V(advice_igraph))
# Plot the Advice network with node coloring based on sex
V(advice_igraph)$color = ifelse (V(advice_igraph)$female ==1, " orange ", " grey ")
plot(advice_igraph, layout=net_layout, edge.color='black', vertex.label = V(advice_igraph))
library('igraph')
igraph_options(vertex.size = 9, vertex.color = 'grey', # vertex.size changes the size of nodes; vertex.color changes the color of nodes
edge.color='gray80', edge.arrow.size=.4, # edge.color changes the color of ties; edge.arrow.size changes the size of tie arrow heads
vertex.label = NA)
advice_igraph <- graph.adjacency(as.matrix.network(advice)) # make an igraph network object from statnet network object
advice_igraph <- set_vertex_attr(advice_igraph,"female",value = read.csv("femaleNode.csv")$female)
net_layout <- layout_with_fr(advice_igraph)
install.packages("igraph")
install.packages("igraph")
messageEdgelist <- read.csv("messageEdgelist.csv")
head(messageEdgelist) # Check the first five rows of the edgelist. Third column is the message count
messages <- matrix(nrow = 66, ncol = 66) # Number of Direct messages sent from i to j
for (i in 1:nrow(messageEdgelist)) { # Read from edgelist
messages[messageEdgelist$SenderId[i], messageEdgelist$ReceiverId[i] ] <- as.numeric(messageEdgelist$MessagesSent[i])
}
for (i in 1:66) { # Remove self-ties (messages sent to self)
messages[i,i] <- as.numeric(0)
}
hundreds_messages <- messages / 100 # Change weights to represent hundred of messages sent
# This will make viewing/interpreting ergm coefficients easier
# ---------------------------------------------------------------------------------------
# Basic descriptive information
# ---------------------------------------------------------------------------------------
summary(advice, print.adj = FALSE)           # summarize the advice From You network
# ---------------------------------------------------------------------------------------
# Visualize networks
# ---------------------------------------------------------------------------------------
library('igraph') # Ignore messages on any objects that are masked
# Set default plot options
igraph_options(vertex.size = 9, vertex.color = 'grey', # vertex.size changes the size of nodes; vertex.color changes the color of nodes
edge.color='gray80', edge.arrow.size=.4, # edge.color changes the color of ties; edge.arrow.size changes the size of tie arrow heads
vertex.label = NA)                       # vertex.label = NA specifies not to display vertex labels in the plot
# Plot the Advice network
advice_igraph <- graph.adjacency(as.matrix.network(advice)) # make an igraph network object from statnet network object
advice_igraph <- set_vertex_attr(advice_igraph,"female",value = read.csv("femaleNode.csv")$female)
net_layout <- layout_with_fr(advice_igraph) # Calculates and stores a spring-embedded layout
# We will re-use this same layout for each plot, so nodes are always in the same place
plot(advice_igraph, layout=net_layout, edge.color='black', vertex.label = V(advice_igraph))
library(igraph)
library(RColorBrewer)
help("brewer.pal")
edges <- read.csv("edge.csv", sep =",")
attrs <- read.csv("attr.csv", sep =",")
setwd("~/Downloads/cs396/cs396-final")
library(igraph)
library(RColorBrewer)
help("brewer.pal")
edges <- read.csv("edge.csv", sep =",")
attrs <- read.csv("attr.csv", sep =",")
actorGraph <- graph.data.frame(edges)
actorGraph <- set_vertex_attr(actorGraph, "group", value = attrs$group)
actorGraph <- set_vertex_attr(actorGraph, "salesrank", value = attrs$salesrank)
actorGraph <- set_vertex_attr(actorGraph, "reviews_num", value = attrs$reviews_num)
actorGraph <- set_vertex_attr(actorGraph, "avg_rating", value = attrs$avg_rating)
comp <- components(actorGraph)
comp
n<-length(comp$csize)
giantGraph <- actorGraph %>%
induced.subgraph(., which(comp$membership == which(comp$csize == sort(comp$csize)[n-2])))
col <- data.frame(group = unique(vertex_attr(giantGraph, "group")), stringsAsFactors = F)
if (length(col$group) >= 3) {
col$color <- brewer.pal(nrow(col), "GnBu")
} else if (length(col$group) == 2){
col$color <- c("Yellow","Green")
} else {
col$color <- c("Yellow")
}
V(giantGraph)$color <- col$color[match(V(giantGraph)$group, col$group)]
giantGraph %>%
plot(.,
layout = layout_with_kk(.), ## force-directed graph layout
edge.arrow.size = .3,
vertex.label = NA,
vertex.size = 4,
vertex.label.cex = .5,
vertex.label.color = 'black')
giantGraph %>%
plot(.,
layout = layout_with_kk(.),
# layout = layout_with_sugiyama(.),
edge.arrow.size = .3,
vertex.size = 4,
vertex.label = NA,
vertex.color = adjustcolor(graph.coreness(.), alpha.f = .3),
vertex.label.cex = .5,
vertex.label.color = 'black',
mark.groups = by(seq_along(graph.coreness(.)), graph.coreness(.), invisible),
mark.shape = 1/4,
mark.col = rainbow(length(unique(graph.coreness(.))),alpha = .1),
mark.border = NA
)
library(xtable)
library(mvtnorm)
library(igraph)
source('MultivarALAAMalt.R')
help("brewer.pal")
edges <- read.csv("edge.csv", sep =",")
attrs <- read.csv("attr.csv", sep =",")
#sample_idx -> sample(nrow(edges), 10000)
#edges <- edges[10000, ]
#attrs <- attrs[10000, ]
actorGraph <- graph.data.frame(edges)
V(actorGraph)
vcount(actorGraph)
actorGraph <- set_vertex_attr(actorGraph, "group", value = attrs$group)
actorGraph <- set_vertex_attr(actorGraph, "salesrank", value = attrs$salesrank)
actorGraph <- set_vertex_attr(actorGraph, "reviews_num", value = attrs$reviews_num)
actorGraph <- set_vertex_attr(actorGraph, "avg_rating", value = attrs$avg_rating)
actorGraph <- set_vertex_attr(actorGraph, "high_rating", value = attrs$high_rating)
actorGraph <- set_vertex_attr(actorGraph, "ranking10", value = attrs$ranking10)
actorGraph <- set_vertex_attr(actorGraph, "ranking20", value = attrs$ranking20)
actorGraph <- set_vertex_attr(actorGraph, "ranking50", value = attrs$ranking50)
actorGraph
comp <- components(actorGraph)
comp
n<-length(comp$csize)
giantGraph <- actorGraph %>%
induced.subgraph(., which(comp$membership == which(comp$csize == sort(comp$csize)[n-3])))
vcount(giantGraph)
data <- as_data_frame(giantGraph, "both")
adj <- as_adj(giantGraph)
adj <- as.matrix(adj)
n <- nrow(adj)
out.degree <-matrix( rowSums(adj), n, 1) # number of ties sent
in.degree <- matrix( colSums(adj) , n, 1 ) # number of ties received
rec.ties <-  matrix( rowSums(adj * t(adj) ), n , 1) # number of ties that are mutual
in.two.star <- matrix( choose(in.degree,2),n,1) #  in-stars refecting dispersion in popularity
out.two.star <- matrix( choose(out.degree,2),n,1) #  out-stars refecting dispersion in activity
mix.two.star <- in.degree*out.degree - rec.ties # correlation between indegree and outdegree
in.three.star <- matrix( choose(in.degree,3),n,1) # furhter measure of in-degree heterogeneity
out.three.star <- matrix( choose(out.degree,3),n,1) # furhter measure of out-degree heterogeneity
triangles <- rowSums( adj* (adj %*% t(adj) )  ) # embedded in transitive triads
covs <- cbind(out.degree,
in.degree,
rec.ties,
in.two.star,
out.two.star,
mix.two.star,
in.three.star,
out.three.star,
triangles,
data$vertices$reviews_num,
data$vertices$avg_rating)
colnames(covs) <- c("indegree",
"outdegree",
"reciprochation" ,
"instar",
"outstar",
"twopath",
"in3star",
"out3star",
"transitive",
"reviews_num",
"avg_rating")
res.0 <- BayesALAAM(y = data$vertices$ranking10,           # dependent variable
ADJ = adj,           # network
covariates = covs,   # covariates
directed = TRUE,     # directed / undirecred network
Iterations = 10000,   # number of iterations
saveFreq = 100,      # print and save frequency
#contagion = 'none'
)  # type of contagion
plot(ts(res.0$Thetas))
plot(ts(res.0$Theta[,1:6]))
plot(ts(res.0$Theta[,7:11]))
## Summarize the results
write.res.table(burnin=1, # should be set sufficiently high
datamat=res.0$Thetas, # the result from BayesALAAM
thin=1, # should be set so that SACF is sufficiently low,
# important for Confidence Intervals
tabname=NULL) # the name appended to the table that is saved
## you can improve the mixing by using a better proposal covariance
Propsigma <- cov(res.0$Thetas)
## which can be used as an argument PropSigma to BayesALAAM. This proposal
## variance (covariance) matrix, directly regulates how big jumps we are
## proposing, as discussed above in the section on ESS.
res.1 <- BayesALAAM(y = data$vertices$ranking50,           # dependent variable
ADJ = adj,           # network
covariates = covs,   # covariates
directed = TRUE,    # directed / undirected network
Iterations = 5000,   # number of iterations
saveFreq = 500,     # print and save frequency
PropSigma = Propsigma )
sim.0 <- get.gof.distribution(NumIterations=500, # number of vectors to draw
res=res.0, # the ALAAM estimation object that
# contains model and results
burnin=100, # no. iterations discarded from
# GOF distribution
thinning = 1000, # no. iterations between
# sample points
contagion ='none') # should be the same as
gof.table(obs.stats= sim.0$stats, # observed statistics included not
# fitted statistics
sim.stats= sim.0$Sav.gof, # simulated goodness-of-fit statistics
name.vec= sim.0$gof.stats.names, # names of statistics calculate,
# not all will be used if undirected
tabname='ALAAMGofalt', # name of file saved
pvalues=TRUE, # posterior predictive p-values
# save.tab ='csv', # save a csv file or a LaTex file
directed=TRUE)
